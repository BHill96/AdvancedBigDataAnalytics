\documentclass{article}

\usepackage{amsmath, amssymb, amsthm}
\usepackage[margin=0.6in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{pgf}
\graphicspath{{Images/}}
\DeclareUnicodeCharacter{2212}{-}

\hypersetup{
    colorlinks=true,
    urlcolor=blue,
}

\title{Forecasting Stock Price Using Sentiment Analysis and LSTM Networks}
\author{Blake Hillier, Grace Li, Joe Puhalla}
\date{March 31, 2020}

\begin{document}
\maketitle

\section{Overview}
Forecasting stock prices is a widely known problem many people have attempted to solve through various models. A common approach is to use only numerical data to predict tomorrow's price. However, investors often use the news about the company's decisions, the public's attitude towards the company, and the state of the economy when developing trading strategies. In this paper, we propose a model using macro-economic variables to predict the future price of a stock, one of which is statements from the Federal Reserve about decisions on economic policies. Our model is comprised of XLNet to perform sentiment analysis on one macro-economic variable and an LSTM Neural Network to combine all the variables while capturing the effect time has on the future stock price. In this paper we first explain the ideas behind XLNet and LSTM Neural Networks. We then explain our implementation of XLNet and LSTM and calculate their mean squared error (MSE) using appropriate subsets of our data. Finally, we explain how we use them together to forecast the stock price and calculate the entire models MSE before making some concluding remarks.

\section{XLNet}
XLNet is an autoregressive pretraining approach for NLP models. Pretraining a model is used to teach a model a broad field before being applied to a specific problem. This allows it to pick up potential nuances within the data and then apply this knowledge to better understand the specific problem. It also allows copies of the same model to be fine tuned to different problems, decreasing the total learning time. Autoregressive pretraining approaches create a conditional probability distribution based on the likelyhood function \begin{equation*}
    p(x)=\prod_{t=1}^{T}p(x_{t}|x_{<t})
\end{equation*} which only sees the relationship between previous text (it can also be modified to only see the relationship between text after the word). This is problematic since most words derive their meaning from context at both the beginning and the end of a sentence. XLNet solves this problem by calculating a distribution based on all the other text in the word by maximizing \begin{equation*}
    \max_{\theta}E_{z\sim Z_{T}}\left[\sum_{t=1}^{T}\log p_{\theta}(x_{z_{t}}|x_{z<t})\right]=E_{z\sim Z_{T}}\left[\sum_{t=1}^{T}\log\frac{e^{g_{\theta}(x_{z<t,z_{t}})l(x_{t}})}{\sum_{x^{'}}e^{g_{\theta}(x_{z<t,z_{t}})l(x^{'})}}\right]
\end{equation*} where $Z_{T}$ is the set of all permutations of text of length $T$, $z \in Z_{T}, x_{z<t}$ is the sequence of text from 1 to $t−1$, and $g_{\theta}$ transforms $x$ to a sequence of hidden words with the first $t-1$ set of words as additional information. They note the permutations don’t affect the actual order of the text sequence, just the factorization of the likelihood function. Because this is based on the likelihood function, it removes the idea each hidden text is independent of the others while still maintaining the benefits through encoding due to  $g_{\theta}$. In order for  $g_{\theta}$ to accomplish this, they split it into two different transforms: the query $g_{\theta}$ which looks at the first $t-1$ words in the permuted order to predict the  $t^{th}$ word, and the content  $h_{\theta}$ which simply encodes the first t words in the permuted order. The one downside to this model is the complexity of the optimization leading to a slower convergence. To reduce this problem, they adjust the equation to \begin{equation*}
    \max_{\theta}E_{z \sim Z_{T}}\left[\log_{p_{\theta}}(x_{z>c}|x_{z\leq t})\right]=E_{z\sim Z_{T}}\left[\sum_{t=c+1}^{|z|}\log p_{\theta}(x_{z_{t}}|x_{z<t})\right]
\end{equation*}
which changes the model to only predict the last $T - c$ words in the permutation order, where $c \approx \frac{T(1+K)}{K}$
for some parameter $K$.

\section{LSTM}

In this paper, the LSTM neural network is uesed to predict the stock price, the input data is the historical stock price and sentiment analysis results. Here, the sentiment based LSTM neural network (named sentiment-LSTM) is aimed to minimize the following loss function:

$$ \ell = min \sum_{t=p+1}^{p+T} \bigg\| X_{t} - \hat{X_{t}} \bigg\|_{2}^{2} $$

Where $T$ denotes the number of prediction time slots, i.e, $t$ = 1, ..., $p$ are the observations (training input data), $t = p+1, ..., p+T$ are the predicts (training output data); and $\hat{X}_{t}$ is given as following:

$$\hat{X}_t = \alpha X_{t}^{A} + \lambda S_{t}^{A} + c = \alpha X_{t}^{A} + \lambda f_{2}\underbrace{((S_{t-i})_{i=1}^{p})}_\text{Sentiment}+c$$

\begin{figure}[htp]
    \centering
    \includegraphics[width=7cm]{LSTM.png}
    \caption{LSTM Procedure}
    \label{fig:LSTM}
\end{figure}

Denote Formula as the training input data. Figure 1 shows the LSTM's structure network, which comprises one or more hidden layers, an output layer and an input layer. LSTM networks’ main advantage is that the hidden layer comprises memory cells. Each memory cell recurrently has a core self-connected linear unit called “ Constant Error Carousel, which provides short-term memory storage and has three gates:

\textbf{Input gate}, which controls the information from a new input to the memory cell, is given by

$$i_{t} = \sigma (W_{i} \times [h_{t-1}, \chi_{t}^{train}] + b_{i})$$
$$\hat{c_{t}} = tanh(W_{c} \times [h_{t-1}, \chi_{t}^{train}] + b_{c} )$$

$h_{t-1}$ is the hidden state at the time step $t-1;i_{t}$ is the output of the input gate layer at the time step $t; \hat{c_{t}} $ is the candidate value to be added to the output at the time step $t; b_{i}$ and $b_{c}$ are biases of the input gate layer and the candidate value computation, respectively; $W_{i}$ and $W_{c}$ are weights of the input gate and the candidate value computation respectively; and $\sigma (x) = 1/(1+e^{-x})$ is the pointwise nonlinear activation function.

\textbf{Forget gate}, which controls the limit up to which a value is saved in the memory, is given by
$$f(t) = \sigma (W_{f} \times [h_{t-1}, \chi_{t}^{train}]+b_{f})$$
where $f_{t}$ is the forget state at the time step $t, W_{f}$ is the weight of the forget gate; and $b_{f}$ is the bias of the forget gate.

\textbf{Output gate}, which controls the information output from the memory cell, is given by

$$ c_{t} = f_{t} \times c_{t-1} + i_{t} \times \hat{c_{t}}$$
$$o_{t} = \sigma (W_{o} \times [h_{t-1}, \chi_{t}^{train}] + b_{o})$$
$$h_{t} = o_{t} \times tanh(c_{t})$$

where new cell state $c_{t}$ are calculated based on the results of the previous two steps; $o_{t}$ is the output at the time step $t; W_{o}$ is the weight of the output gate; and $b_{o}$ is the bias of the out put gate. \\

\section{Experiment}
Because our model has multiple core algorithms, we need to calibrate each main component individually as well as when they are all together to ensure we are obtaining an optimal accuracy. This section will discuss the data we use, how each algorithm performs on their own, and how they perform when put together.
\subsection{Data}
Our data consisted of macroeconomic data and the previous stock priced. The macroeconomic data consisted of the quarterly GDP, monthly CPI, monthly unemployment rate, monthly inflation rate, the ten-year treasury rate, the 1 year LIBOR daily, and the statements from the Federal Reserve. All the data ranges from the beginning of the year 2000 to the end of 2014. Since our stock is daily data, all previous data were duplicated into daily data and aligned with the stock information.
\subsection{Sentiment Analysis}
We used pytorch's implementation of XLNet-base for our model. Sentiment was assigned to the Fed's Statements by looking at the percent change of the UNH stock. If the stock increased, the sentiment was positive, and negative otherwise. We then tested the accuracy of the XLNet by randomly selecting $80\%$ of the data to train, and the remaining $20\%$ to test. This was done using a GPU on Google's Colab. We had to carefully select our batch size, maximum statement length, and epoch combinations carefully due to memory constraints. This posed an interesting problem for us since a larger maximum statement size allows more of the Fed's statement to be considered for sentiment, but requires a smaller batch size resulting in severe over fitting. A smaller statement size reduces the amount of information available, but allows a bigger batch size leading to better generalizations. After some testing we found a maximum statement length of 128, batch size of 24, and 10 epochs produced the best accuracy of $77.1\%$.
\subsection{LSTM Stock Prediction}
\begin{figure}
\begin{minipage}{0.5\textwidth}
    \centering
    \includegraphics[width=9cm]{LSTMResult.png}
    \caption{Predicted vs. Actual Stock Price}
    \label{fig:LSTMForecast}
\end{minipage}
\begin{minipage}{0.5\textwidth}
    \centering
    \includegraphics[width=9cm]{LSTMMSE.png}
    \caption{MSE by Number of Epochs}
    \label{fig:LSTMResult}
\end{minipage}
\end{figure}

The LSTM network we use includes four layers each with a dropout rate of twenty percent. The layers are of size $256,128,64,32$ and then the final layer. We sampled through several activation functions, starting with linear activation, and determined the ReLu activation to provide the best accuracy of the model. In order to determine the accuracy of the model, we plot both the predicted and actual stock price values of UNH. We then determine the mean squared error between the predicted and actual prices. We sampled across several amounts of epochs $(5,10,20,50)$ and batch sizes $(8,16,32, 64)$ in order to determine the best architecture for the model. For simplicity purposes, we used the already given ‘adam’ optimizer. Our feature set for the model were daily measures of price, GDP, CPI, inflation, unemployment, LIBOR, and the 10-year treasury yield. GDP data was given quarterly and thus had to be converted to daily data. In addition, CPI, inflation, and unemployment were given as monthly data and were converted to daily data. Our train and test data were split 50-50.
With a batch size of 8, the 20 and 50 epoch sized networks caused memory issues and thus were unable to be completed. A batch size of 64, and 50 epochs yielded the lowest MSE among all models $(\ref{fig:LSTMForecast})$. More tests need to be conducted in order to determine the most accurate model. Furthermore, the number of layers needs to be varied as well as the optimizer used. Tests need to be done to determine which features contribute the most to the predicting power of our model. Sentiment scores of the FOMC transcripts also need to be added as features of the model. The preliminary results provide for a proof of concept for our model and give promise to further tests with more features.  
\subsection{XLNet and LSTM}
Using the optimal model parameters through the previous sections, we created a pipeline using both models. We first trained the XLNet on the entire text data, and then predicted the sentiment on the same dataset. This was then merged with the input data for the LSTM, and was trained using a portion of the stock data. Once trained, we validated it with the last 2014 data points to obtain the MSE: 25.226. This is lower than our previous tests with the LSTM, showing the capability of XLNet improving our forecasting accuracy. Figure $\ref{fig:XLNetLSTMForcast}$ shows our test case after training with XLNet and the LSTM model. 
\begin{figure}
    \centering
    \scalebox{0.5}{\input{StockPredXLNet.pgf}}
    \caption{Forecast with XLNet and LSTM compared with the actual price}
    \label{fig:XLNetLSTMForcast}
\end{figure}


\section{Conclusion}
In this paper we attempt to build a stock forecasting model using sentiment analysis with XLNet and then forecast using an LSTM network. Even though our data only contained a few features, of which all but one were macroeconomic, we still obtained results showing promise with this model structure. One big downside of our model is the variance in the accuracy of the XLNet. While it is possible to get $77.8\%$, when training the model we would also often get accuracy's near $60\%$, or even $40\%$. We believe this is due to our low amount of data, and hope it will also improve with a better sentiment measure. Using a GPU with more memory would allow us to increase our maximum statement length which could also improve XLNet's accuracy. We also hope by carefully selecting more features, including micro-economic features, we can increase our models accuracy, and plan on increasing the time duration of our data set. Lastly, while judging the MSE of the predicted value is a great way of understanding the model's accuracy, simulating a trading strategy using the model would allow us to more concretely understand how usable our model really is. For a full look at the code, check out our \href{https://github.com/BHill96/AdvancedBigDataAnalytics}{github.}

\begin{thebibliography}{9}
\bibitem{XLNet} 
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 
\textit{XLNet: Generalized Autoregresive Pretraining for Language Understanding}. 
Carnegie Mellon University, 2Google AI Brain Team, Jan $2^{nd}$ 2020.

\bibitem{LSTM} 
Xinyi Li, Yinchuan Li, Hongyang Yang, Liuqing Yang, Xiao-Yang Liu.
\textit{DP-LSTM: Differential Privacy-inspired LSTM for Stock Prediction Using Financial News}. Columbia University, Beijing Institute of Technology.

\bibitem{knuthwebsite} 
Github LSTM Stock Prediction,
\\\url{https://github.com/laxmimerit/Google-Stock-Price-Prediction-Using-RNN---LSTM/blob/master/Google%20Stock%20Price%20Prediction%20Using%20RNN-%20LSTM.ipynb}
\end{thebibliography}

\end{document}

